{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import boto3\n",
    "from configparser import ConfigParser\n",
    "\n",
    "# check directory    \n",
    "outdir = './problem2_result'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "if os.path.exists(outdir + '/compiled_result.csv'):\n",
    "    os.remove(outdir + '/compiled_result.csv')\n",
    "    \n",
    "# remove all handlers associated with the toot logger object\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "    \n",
    "# set up logging to file\n",
    "logging.basicConfig(filename= outdir + '/missing_data_log.log', filemode='w', level=logging.INFO,\n",
    "                   format = '%(asctime)s%(levelname)-8s%(message)s')\n",
    "\n",
    "# opening and parse EDGAR Log File Data Set html\n",
    "edgarLogUrl = 'https://www.sec.gov/dera/data/edgar-log-file-data-set.html'\n",
    "edgarLogPage = BeautifulSoup(urlopen(edgarLogUrl),'lxml')\n",
    "logging.info('Opening and parse EDGAR Log File Data Set html.')\n",
    "\n",
    "# get log file html of specified year\n",
    "year = '2010'\n",
    "try:\n",
    "    for link in edgarLogPage.findAll('a'):\n",
    "        if link.text == year:\n",
    "            edgarLogFiles = BeautifulSoup(urlopen('https://www.sec.gov' + link.get('href')),'lxml')\n",
    "            logging.info('Get log file html of specified year.')\n",
    "            break\n",
    "except Exception:\n",
    "    loggint.warning('####Error, no ',year,'log file data set found')\n",
    "    sys.exit('####Error, no ',year,'log file data set found')\n",
    "\n",
    "# get url of each month\n",
    "monthList=[]\n",
    "for i, link in enumerate(edgarLogFiles.findAll('a')):\n",
    "    if(re.match(r'.*01.zip$',link.text)):\n",
    "        monthList.insert(12-i,link.get('href'))\n",
    "logging.info('Get url of each month.')\n",
    "\n",
    "# define a function, use box plot concept\n",
    "# lower inner fence: Q1-1.5*IQ\n",
    "# upper inner fenceï¼›Q3+1.5*IQ\n",
    "# as fences to check anomalies.\n",
    "# df, the dataframe of orignial dataset\n",
    "# col_name, the column name to be checked\n",
    "# return cleaned data (after removing anomalies) in a new dataframe\n",
    "def remove_outlier(df,col_name):\n",
    "    q1 = df[col_name].quantile(0.25)\n",
    "    q3 = df[col_name].quantile(0.75)\n",
    "    iqr = q3 -q1 #Interquartile range\n",
    "    fence_low = q1 - 1.5 * iqr\n",
    "    fence_high = q3 + 1.5 * iqr\n",
    "    if(iqr == 0):\n",
    "        df_out = df[df[col_name] == fence_low]\n",
    "    else:\n",
    "        df_out = df[(df[col_name] > fence_low) & (df[col_name] < fence_high)]\n",
    "    return df_out\n",
    "\n",
    "if len(monthList) != 12:\n",
    "    loggint.warning('####Error, there is something wrong with each month log file in ',year,'.')\n",
    "    sys.exit('####Error, there is something wrong with each month log file in ',year,'.')\n",
    "    \n",
    "for i in range(0, 1):\n",
    "    # download zip and parse csv file\n",
    "    content = requests.get(monthList[i])\n",
    "    zf = zipfile.ZipFile(BytesIO(content.content))\n",
    "    for name in zf.namelist():\n",
    "        if (re.match(r'.*.csv$',name)):\n",
    "            df = pd.read_csv(zf.open(name)) \n",
    "    logging.info('Download ' + year + '-' + str(i + 1) + '-01 zip and parse csv file')\n",
    "\n",
    "    # fill 'unknown' for missing data in column 'browser'\n",
    "    df['browser'].fillna('unknown', inplace = True)\n",
    "    logging.info('Fill \\'unknown\\' for missing data in column \\'browser\\'')\n",
    "\n",
    "    # fill average for missing data in column 'size'\n",
    "    df['size'].fillna(df['size'].mean(), inplace = True)\n",
    "    logging.info('Fill average for missing data in column \\'size\\'')\n",
    "\n",
    "    # check for anomalies according column 'code' and remove anomalies\n",
    "    df1 = remove_outlier(df, 'code')\n",
    "    logging.info('Check for anomalies according column \\'code\\' and remove anomalies.')\n",
    "    \n",
    "    # compute summary metrics\n",
    "    summary = df1.describe()\n",
    "    logging.info('Compute summary metrics.')\n",
    "    \n",
    "    # compile data and summary into one file\n",
    "    df1.to_csv(outdir + '/compiled_result.csv', mode = 'a',index = False, header = None)\n",
    "    summary.to_csv(outdir + '/compiled_result.csv', mode = 'a')\n",
    "    logging.info('Compile data and summary into one file.')\n",
    "\n",
    "# zip the tables and log file in result.zip\n",
    "logging.info('Zip the tables and log file in result.zip')\n",
    "resultPath = os.path.join(os.getcwd(),'problem2_result')\n",
    "shutil.make_archive(resultPath,'zip',resultPath)\n",
    "\n",
    "# use AWS S3\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "aws_key = config.get('aws','aws_key')\n",
    "aws_secret = config.get('aws','aws_secret')\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id = aws_key,\n",
    "    aws_secret_access_key = aws_secret,)\n",
    "# before using AWS S3 bucket, make sure configuring aws credentials\n",
    "try:\n",
    "    s3 = session.resource('s3')\n",
    "except Exception:\n",
    "    logging.warn('######Error, please check aws configuration.')\n",
    "    sys.exit('######Error, please check aws configuration.')\n",
    "\n",
    "# create new bucket\n",
    "bucketName = 'info7390-group6-missing-data'\n",
    "s3.create_bucket(Bucket = bucketName)\n",
    "\n",
    "# upload result.zip to S3 bucket\n",
    "s3.meta.client.upload_file(os.path.join(os.getcwd(),'problem2_result.zip'),bucketName,'problem2_result.zip')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
